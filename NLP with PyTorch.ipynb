{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring common applications of NLP\n",
    "While I scratch things down for this exploration, it will be messy. I'm looking to dive into functionality first and polish later.\n",
    "\n",
    "Some ideas for NLP Applications:\n",
    "\n",
    "* spell checking and grammatical correction\n",
    "* text classification, summarization, mining\n",
    "* information retrieval and information extraction\n",
    "* question answering\n",
    "* sentiment analysis\n",
    "* support applications, such as: stemming, POS tagging, semantic tagging, and partial parsing\n",
    "* natural language programming code generators, query generators\n",
    "* machine translation\n",
    "* speech analysis and generation systems\n",
    "* conversational agents (e.g., chat bots)\n",
    "* document generation (or computer support in document writing)\n",
    "\n",
    "Ideas taken from my notes from CSCI 4152/6509 @ Dalhousie University, taught by Vlado Keselj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import matplotlib as plt\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Talk Tensors\n",
    "I will likely be using PyTorch for my NLP models, so going over the basics is always useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function for tensor info\n",
    "\n",
    "def describe(x):\n",
    "    print(\"Type: {}\".format(x.type()))\n",
    "    print(\"Shape/size: {}\".format(x.shape))\n",
    "    print(\"Values: \\n{}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-5.5196e-13,  4.5886e-41, -1.4018e+05],\n",
      "        [ 4.5886e-41, -5.4010e-13,  4.5886e-41]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.6312, 0.2235, 0.7323],\n",
      "        [0.5298, 0.6733, 0.7855]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-0.1161, -0.3188,  0.1020],\n",
      "        [-0.4853, -0.0160,  1.5869]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#Create random tensor by specifying dimensions\n",
    "describe(torch.Tensor(2, 3))\n",
    "#Uniform distro initialize [0,1)\n",
    "describe(torch.rand(2,3)) # uniform random\n",
    "describe(torch.randn(2,3))  # random normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "#Tensors filled with same scalar\n",
    "describe(torch.zeros(2,3))\n",
    "#or\n",
    "x = torch.ones(2,3)\n",
    "describe(x)\n",
    "x.fill_(5) # _ indicates and in-place operation that will modify content in place\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Type: torch.DoubleTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0.8535, 0.0760, 0.6408],\n",
      "        [0.4872, 0.6421, 0.9031]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Using a list\n",
    "x = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "describe(x)\n",
    "\n",
    "#To/from NumPy\n",
    "import numpy as np\n",
    "y = np.random.rand(2,3)\n",
    "describe(torch.from_numpy(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-1.3372, -0.0507,  1.3860],\n",
      "        [-1.0321,  0.7932, -1.0762]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-2.6744, -0.1014,  2.7720],\n",
      "        [-2.0641,  1.5864, -2.1524]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[-2.6744, -0.1014,  2.7720],\n",
      "        [-2.0641,  1.5864, -2.1524]])\n"
     ]
    }
   ],
   "source": [
    "#Operations\n",
    "x = torch.randn(2,3)\n",
    "describe(x)\n",
    "describe(torch.add(x, x))\n",
    "#or\n",
    "describe(x + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([6])\n",
      "Values: \n",
      "tensor([0, 1, 2, 3, 4, 5])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "#Dimension operations\n",
    "x = torch.arange(6) #Initalization with a range of values\n",
    "describe(x)\n",
    "#changing the 'view' of the tensor\n",
    "x = x.view(2,3)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([3])\n",
      "Values: \n",
      "tensor([3, 5, 7])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2])\n",
      "Values: \n",
      "tensor([ 3, 12])\n"
     ]
    }
   ],
   "source": [
    "#Dim here = dimension to reduce\n",
    "describe(torch.sum(x, dim=0)) #Reduce rows = sum cols\n",
    "describe(torch.sum(x, dim=1)) #Reduce cols = sum rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      "tensor([[0, 1]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Indexing/slicing\n",
    "\n",
    "x = torch.arange(6).view(2,3)\n",
    "describe(x)\n",
    "describe(x[:1,:2]) #Up to row 1, up to col 2 (not inclusive)\n",
    "describe(x[0][1]) #row 0, column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[0, 2],\n",
      "        [3, 5]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "#Fancy indexing (non contiguous)\n",
    "indices = torch.LongTensor([0,2]) #Long tensor required for indexing\n",
    "describe(torch.index_select(x, dim=1, index=indices)) \n",
    "\n",
    "indices = torch.LongTensor([0,0])\n",
    "describe(torch.index_select(x, dim=0, index=indices)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([4, 3])\n",
      "Values: \n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 6])\n",
      "Values: \n",
      "tensor([[0, 1, 2, 0, 1, 2],\n",
      "        [3, 4, 5, 3, 4, 5]])\n",
      "Type: torch.LongTensor\n",
      "Shape/size: torch.Size([2, 2, 3])\n",
      "Values: \n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5]]])\n"
     ]
    }
   ],
   "source": [
    "#Concat\n",
    "x = torch.arange(6).view(2,3)\n",
    "describe(x)\n",
    "describe(torch.cat([x, x], dim=0)) #Append rows\n",
    "describe(torch.cat([x,x], dim=1)) #Append columns\n",
    "describe(torch.stack([x,x])) #Appending 2d tensor, creates new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[1., 2.],\n",
      "        [1., 2.],\n",
      "        [1., 2.]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[ 3.,  6.],\n",
      "        [12., 24.]])\n"
     ]
    }
   ],
   "source": [
    "#Linear algebra\n",
    "x1 = torch.arange(6, dtype=torch.float32).view(2,3)\n",
    "describe(x1)\n",
    "x2 = torch.ones(3,2)\n",
    "x2[:,1] += 1\n",
    "describe(x2)\n",
    "describe(torch.mm(x1, x2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Computational Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Gradient bookkeeping\n",
    "\n",
    "#Requires grad is built into torch tensors to flag the model to \n",
    "#Track the gradient at the tensor & gradient function\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "describe(x)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([2, 2])\n",
      "Values: \n",
      "tensor([[21., 21.],\n",
      "        [21., 21.]], grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#After using x in computation\n",
    "y = (x + 2) * (x + 5) + 3\n",
    "describe(y)\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([])\n",
      "Values: \n",
      "21.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "describe(z)\n",
    "#Initiate a backward pass (would be training for a model)\n",
    "z.backward()\n",
    "print(x.grad is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"When you create a tensor with requires_grad=True, you are requiring PyTorch to manage bookkeeping information that computes gradients. First, PyTorch will keep track of the values of the forward pass. Then, at the end of the computations, a single scalar is used to compute a backward pass. The backward pass is initiated by using the backward() method on a tensor resulting from the evaluation of a loss function.\n",
    "The backward pass computes a gradient value for a tensor object that participated in the forward pass.\n",
    "In general, the gradient is a value that represents the slope of a function output with respect to the function input. In the computational graph setting, gradients exist for each parameter in the model and can be thought of as the parameterâ€™s contribution to the error signal. In PyTorch, you can access the gradients for the nodes in the computational graph by using the .grad member variable. Optimizers use the .grad variable to update the values of the parameters.\" (pp.23-24, Rao &McMahan, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Tensor Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.1103, 0.8470, 0.3410],\n",
      "        [0.0517, 0.3652, 0.4733],\n",
      "        [0.7898, 0.9979, 0.7675]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 3, 3])\n",
      "Values: \n",
      "tensor([[[0.1103, 0.8470, 0.3410],\n",
      "         [0.0517, 0.3652, 0.4733],\n",
      "         [0.7898, 0.9979, 0.7675]]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 3])\n",
      "Values: \n",
      "tensor([[0.1103, 0.8470, 0.3410],\n",
      "        [0.0517, 0.3652, 0.4733],\n",
      "        [0.7898, 0.9979, 0.7675]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([5, 3])\n",
      "Values: \n",
      "tensor([[3.4073, 6.6782, 4.9442],\n",
      "        [5.7531, 4.3199, 6.4622],\n",
      "        [3.0486, 6.2562, 6.1288],\n",
      "        [6.6474, 4.1279, 5.8314],\n",
      "        [5.7852, 3.5584, 3.9229]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([1, 2])\n",
      "Values: \n",
      "tensor([[0.8900, 1.6407]])\n"
     ]
    }
   ],
   "source": [
    "#1. Create a 2D tensor and then add a dimension of size 1 inserted at dimension 0.\n",
    "a = torch.rand(3, 3)\n",
    "describe(a)\n",
    "a = a.unsqueeze(0) #Unsqueeze no longer seems to work in place\n",
    "describe(a)\n",
    "#2. Remove the extra dimension you just added to the previous tensor.\n",
    "a = a.squeeze(0)\n",
    "describe(a)\n",
    "#3. Create a random tensor of shape 5x3 in the interval [3, 7)\n",
    "a = torch.rand(5,3).uniform_(3,7)\n",
    "describe(a)\n",
    "#4. Create a tensor with values from a normal distribution (mean=0, std=1).\n",
    "a = torch.randn(1,2)\n",
    "describe(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [4]])\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 1])\n",
      "Values: \n",
      "tensor([[0.8143],\n",
      "        [0.8853],\n",
      "        [0.9599]])\n",
      "Batch matrix-matrix product:\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 4])\n",
      "Values: \n",
      "tensor([[[1.5171, 1.0205, 1.9006, 1.3833],\n",
      "         [1.0590, 1.1029, 1.5360, 1.2021],\n",
      "         [0.9381, 0.6295, 1.2227, 0.8907],\n",
      "         [2.2295, 1.4544, 2.6187, 2.0427]],\n",
      "\n",
      "        [[2.3655, 1.2813, 1.0573, 2.3138],\n",
      "         [1.1838, 0.5576, 0.5598, 1.1609],\n",
      "         [1.6539, 0.8487, 0.8366, 1.6434],\n",
      "         [2.6953, 1.6405, 1.5004, 2.6969]],\n",
      "\n",
      "        [[0.4632, 0.6717, 1.3089, 0.9911],\n",
      "         [0.3524, 0.6966, 1.5733, 0.7359],\n",
      "         [0.9599, 1.1777, 1.7903, 1.0912],\n",
      "         [1.3014, 1.4758, 2.0686, 1.3581]]])\n"
     ]
    }
   ],
   "source": [
    "#5. Retrieve the indexes of all the nonzero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).\n",
    "a = torch.Tensor([1, 1, 1, 0, 1])\n",
    "print(torch.nonzero(a))\n",
    "#6. Create a random tensor of size (3,1) and then horizontally stack four copies together.\n",
    "a = torch.rand(3,1)\n",
    "a.expand(3, 4)\n",
    "describe(a)\n",
    "#7. Return the batch matrix-matrix product of two three-dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).\n",
    "a = torch.rand(3, 4, 5)\n",
    "b = torch.rand(3, 5, 4)\n",
    "c = torch.bmm(a, b)\n",
    "print('Batch matrix-matrix product:')\n",
    "describe(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch matrix-matrix product of 3D & 2D:\n",
      "Type: torch.FloatTensor\n",
      "Shape/size: torch.Size([3, 4, 4])\n",
      "Values: \n",
      "tensor([[[1.0435, 1.4942, 1.5699, 1.4485],\n",
      "         [0.7644, 0.9854, 1.0839, 0.8961],\n",
      "         [0.7661, 0.8133, 0.6325, 1.1026],\n",
      "         [1.5191, 1.9652, 2.0571, 1.8838]],\n",
      "\n",
      "        [[1.1463, 1.5522, 1.6381, 1.3833],\n",
      "         [0.5495, 0.7978, 0.7697, 0.7563],\n",
      "         [0.9601, 1.0818, 1.1293, 1.2079],\n",
      "         [1.6021, 1.4269, 1.4266, 2.0614]],\n",
      "\n",
      "        [[0.7948, 0.7197, 0.7924, 0.9401],\n",
      "         [0.9730, 0.5689, 1.0061, 1.4761],\n",
      "         [1.2304, 1.4277, 1.5134, 1.5557],\n",
      "         [1.4274, 1.8596, 1.8209, 1.7938]]])\n"
     ]
    }
   ],
   "source": [
    "#8. Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).\n",
    "b = torch.rand(5,4)\n",
    "c = torch.bmm(a, b.unsqueeze(0).expand(a.size(0), *b.size()))\n",
    "print('Batch matrix-matrix product of 3D & 2D:')\n",
    "describe(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['auroras', 'only', 'come', 'out', 'at', 'night', ',', 'except', 'in', 'the', 'winter', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#Install a default trained pipeline package 'en' = english\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#Aurora is my hedgehog's name. tehe\n",
    "text = \"Auroras only come out at night, except in the winter.\"\n",
    "#Using list comprehension for english language tokenization using spacy\n",
    "print([str(token) for token in nlp(text.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snow', 'white', 'and', 'the', 'seven', 'degrees', '#makeamoviecold', '@midnight', ':-)']\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing a tweet using NLTK\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet = u\"Snow White and the Seven Degrees #MakeAMovieCold@midnight:-)\"\n",
    "tokenizer = TweetTokenizer() #Understands hashtags and emojis\n",
    "print(tokenizer.tokenize(tweet.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams\n",
    "Generating n-grams from a text is straightforward enough, as illustrated above, but packages like spaCy and NLTK provide convenient methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mary', ',', \"n't\"], [',', \"n't\", 'slap'], [\"n't\", 'slap', 'green'], ['slap', 'green', 'witch'], ['green', 'witch', '.']]\n"
     ]
    }
   ],
   "source": [
    "def n_grams(text, n):\n",
    "    '''\n",
    "    takes tokens on text, returns a list of n-grams\n",
    "    '''\n",
    "    #From index i to i+n (3 in our test case, non-inclusive)\n",
    "    return [text[i:i+n] for i in range(len(text) - n+1)] #range -n+1 to not overflow indices\n",
    "\n",
    "cleaned = ['mary', ',', \"n't\", 'slap', 'green', 'witch', '.']\n",
    "print(n_grams(cleaned, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmas and Stems\n",
    "Lemmas are the root forms of words\n",
    "Stemming uses handcrafted rules to strip endings of words to reduce them to *stems*.\n",
    "\n",
    "Spacy uses WordNet for lemmas, does not have direct stem functions.\n",
    "\n",
    "NLTK has a stemmer which we reference the notes from:\n",
    "https://stackabuse.com/python-for-nlp-tokenization-stemming-and-lemmatization-with-spacy-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he --> he\n",
      "was --> be\n",
      "running --> run\n",
      "late --> late\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"he was running late\")\n",
    "for token in doc:\n",
    "    print('{} --> {}'.format(token, token.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute --> comput\n",
      "computer --> comput\n",
      "computed --> comput\n",
      "computing --> comput\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "tokens = ['compute', 'computer', 'computed', 'computing']\n",
    "for token in tokens:\n",
    "    print('{} --> {}'.format(token, stemmer.stem(token)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-Speech (POS) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary - PROPN\n",
      "slapped - VERB\n",
      "the - DET\n",
      "green - PROPN\n",
      "witch - NOUN\n",
      ". - PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Mary slapped the green witch.\")\n",
    "for token in doc:\n",
    "    print('{} - {}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking and Named Entity Recognition (NER)\n",
    "\n",
    "Additional reference used here:\n",
    "https://blog.devgenius.io/named-entity-recognition-ner-nlp-python-6504d5843f98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary - NP\n",
      "the green witch - NP\n"
     ]
    }
   ],
   "source": [
    "#Identifying all the nouns in the document\n",
    "doc = nlp(u\"Mary slapped the green witch.\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('{} - {}'.format(chunk, chunk.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary Marigold - PERSON - People, including fictional\n",
      "Google Studios - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Mary Marigold slapped the green witch in Google Studios.\")\n",
    "#Named entities\n",
    "for entities in doc.ents:\n",
    "    print('{} - {} - {}'.format(entities, entities.label_, spacy.explain(entities.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mary Marigold\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " slapped the green witch in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google Studios\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c4ab2260c75d47c496ba291c87a44a7b-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mary</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Marigold</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">slapped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">green</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">witch</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Google</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Studios.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-4\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 920.0,89.5 920.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,354.0 L928.0,342.0 912.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-5\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1100.0,2.0 1100.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,354.0 L1108.0,342.0 1092.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c4ab2260c75d47c496ba291c87a44a7b-0-7\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c4ab2260c75d47c496ba291c87a44a7b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1440.0,354.0 L1448.0,342.0 1432.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with Neural Networks\n",
    "\n",
    "I'm not going to go over the basics of Neural networks, as I've already built functionality explanations in my portfolio using just NumPy for maximum component clarity.\n",
    "\n",
    "See page on Linear Regression for dive in gradient descent and\n",
    "Neural Networks for multilayer perceptron building:\n",
    "https://github.com/No-Arms/Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        #Input = size of input features\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim,1) #First fully connect layer\n",
    "    def forward(self, x_in):\n",
    "        '''\n",
    "        in shape = (batch, num_features)\n",
    "        out shape = tensor shape (batch,)\n",
    "        '''\n",
    "        return torch.sigmoid(self.fc1(x_in)).squeeze() #squeeze might not work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification\n",
    "Classifying the restaurant reviews on Yelp as positive of negative.\n",
    "\n",
    "Dataset found at : https://www.kaggle.com/datasets/ilhamfp31/yelp-review-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class                                             Review\n",
      "0      1  Last summer I had an appointment to get new ti...\n",
      "1      2  Friendly staff, same starbucks fair you get an...\n",
      "2      1  The food is good. Unfortunately the service is...\n",
      "3      2  Even when we didn't have a car Filene's Baseme...\n",
      "4      2  Picture Billy Joel's \\\"Piano Man\\\" DOUBLED mix...\n",
      "Index(['Class', 'Review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "'''Have to manually label our columns here.\n",
    "Also need to leave the index column because otherwise the \"class\" column is considered an index, not a column.'''\n",
    "colNames = ['Class','Review']\n",
    "testD = pd.read_csv('datasets/yelp_review_polarity_csv/test.csv', header=0, names=colNames)\n",
    "print(testD.head())\n",
    "print(testD.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* Rao, D., & McMahan, B. (2019). *Natural language processing with pytorch: Build intelligent language applications using Deep Learning.* O'Reilly. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('mlops')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f909869fb803169ad77fc6778195d8c6988ec350b555e2703b5d10f2775badb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
